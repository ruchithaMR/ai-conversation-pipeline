{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- Set up client ---\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "XTmoWm2X_zBJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Conversation storage ---\n",
        "conversation_history = []\n",
        "\n",
        "def add_message(role, content):\n",
        "    conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "def get_groq_response():\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            messages=conversation_history\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting response: {e}\")\n",
        "        return \"I apologize, but I'm having trouble responding at the moment.\""
      ],
      "metadata": {
        "id": "IG3-jr_E_1If"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simplified Summarization function ---\n",
        "def summarize_history():\n",
        "    \"\"\"Summarize the conversation and add it as a system message\"\"\"\n",
        "    global conversation_history\n",
        "\n",
        "    # Remove any existing summary\n",
        "    if conversation_history and conversation_history[0][\"role\"] == \"system\" and \"[Summary]\" in conversation_history[0][\"content\"]:\n",
        "        conversation_history.pop(0)\n",
        "\n",
        "    # Get the last 6 messages (3 user + 3 assistant)\n",
        "    if len(conversation_history) < 4:\n",
        "        print(\"Not enough messages to summarize\")\n",
        "        return\n",
        "\n",
        "    messages_to_summarize = conversation_history[-6:]  # Last 3 exchanges\n",
        "\n",
        "    try:\n",
        "        # Create a simple prompt for summarization\n",
        "        prompt = \"Please summarize the following conversation in 1-2 sentences:\\n\\n\"\n",
        "        for msg in messages_to_summarize:\n",
        "            role = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
        "            prompt += f\"{role}: {msg['content']}\\n\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes conversations concisely.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=100,\n",
        "            temperature=0.1\n",
        "        )\n",
        "        summary_text = response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summarization: {e}\")\n",
        "        # Create a simple fallback summary\n",
        "        user_messages = [msg[\"content\"] for msg in messages_to_summarize if msg[\"role\"] == \"user\"]\n",
        "        summary_text = f\"Conversation about: {', '.join(user_messages[:2])}\"\n",
        "\n",
        "    # Insert summary at the top\n",
        "    conversation_history.insert(0, {\"role\": \"system\", \"content\": f\"[Summary]: {summary_text}\"})\n",
        "    return summary_text\n"
      ],
      "metadata": {
        "id": "8Y7mOIJRAKXP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pretty print history ---\n",
        "def print_history():\n",
        "    print(\"\\n--- Conversation History ---\")\n",
        "    for idx, msg in enumerate(conversation_history, 1):\n",
        "        role = msg[\"role\"].upper()\n",
        "        content = msg['content']\n",
        "        if len(content) > 100:\n",
        "            content = content[:97] + \"...\"\n",
        "        print(f\"{idx}. {role}: {content}\")\n",
        "    print(\"---------------------------\\n\")\n",
        "\n",
        "# --- Continuous chat ---\n",
        "conversation_run_count = 0\n",
        "K = 3  # summarize every 3 chats\n",
        "\n",
        "def start_chat():\n",
        "    global conversation_run_count\n",
        "\n",
        "    print(\"Type 'exit' or 'quit' to end the chat.\")\n",
        "    print(\"Type 'history' to view current conversation history.\")\n",
        "    print(\"Type 'summary' to manually summarize the conversation.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"\\n[Chat ended]\")\n",
        "            break\n",
        "        elif user_input.lower() == \"history\":\n",
        "            print_history()\n",
        "            continue\n",
        "        elif user_input.lower() == \"summary\":\n",
        "            summary = summarize_history()\n",
        "            print(f\"\\nSummary: {summary}\")\n",
        "            print_history()\n",
        "            continue\n",
        "\n",
        "        add_message(\"user\", user_input)\n",
        "        assistant_reply = get_groq_response()\n",
        "        add_message(\"assistant\", assistant_reply)\n",
        "\n",
        "        conversation_run_count += 1\n",
        "\n",
        "        # Keep only the last 10 messages\n",
        "        if len(conversation_history) > 10:\n",
        "            conversation_history.pop(0)  # Remove the oldest message\n",
        "\n",
        "        # Summarize after every K chats\n",
        "        if conversation_run_count % K == 0:\n",
        "            print(f\"\\n[Summarizing conversation after {K} exchanges]\")\n",
        "            summary = summarize_history()\n",
        "            print(f\"Summary: {summary}\")\n",
        "            print_history()\n",
        "\n",
        "        print(f\"Assistant: {assistant_reply}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "sm3EQ2vaASM5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Conversation Management System with Summarization\")\n",
        "    print(\"================================================\")\n",
        "start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7b-MW4WAXBO",
        "outputId": "4a37d0ce-e4ae-4960-f788-b49d7d3a40c3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation Management System with Summarization\n",
            "================================================\n",
            "Type 'exit' or 'quit' to end the chat.\n",
            "Type 'history' to view current conversation history.\n",
            "Type 'summary' to manually summarize the conversation.\n",
            "\n",
            "You: hi good morning\n",
            "Assistant: Good morning! Hope you're having a great start to the day! Is there something I can help you with or would you like to chat?\n",
            "You: i just woke up\n",
            "Assistant: Welcome to the land of the awake! It can take a little while to shake off the sleepiness, but I'm here to help get you started. How about a gentle morning question: Did you have any interesting dreams or are you looking forward to something specific today?\n",
            "You: i want to go college\n",
            "\n",
            "[Summarizing conversation after 3 exchanges]\n",
            "Summary: The user woke up and is having a gentle morning conversation, sharing their goal of attending college. The assistant is offering support and guidance, inquiring about the user's interests and plans for college, such as potential majors or career paths, and whether they've started exploring colleges or universities.\n",
            "\n",
            "--- Conversation History ---\n",
            "1. SYSTEM: [Summary]: The user woke up and is having a gentle morning conversation, sharing their goal of at...\n",
            "2. USER: hi good morning\n",
            "3. ASSISTANT: Good morning! Hope you're having a great start to the day! Is there something I can help you with...\n",
            "4. USER: i just woke up\n",
            "5. ASSISTANT: Welcome to the land of the awake! It can take a little while to shake off the sleepiness, but I'm...\n",
            "6. USER: i want to go college\n",
            "7. ASSISTANT: That's great to hear! College can be a fantastic experience, a time to learn, grow, and explore y...\n",
            "---------------------------\n",
            "\n",
            "Assistant: That's great to hear! College can be a fantastic experience, a time to learn, grow, and explore your interests. What are you hoping to study or achieve in college? Are you thinking of pursuing a specific major or career path?\n",
            "\n",
            "Also, have you already started looking into colleges or universities, or is this a goal you're just starting to work towards? I'm here to help and offer any guidance or advice I can!\n",
            "You: exit\n",
            "\n",
            "[Chat ended]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- Set up client ---\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# --- JSON Schema for Information Extraction ---\n",
        "user_info_schema = {\n",
        "    \"name\": \"extract_user_information\",\n",
        "    \"description\": \"Extract user information from the conversation\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's full name\"\n",
        "            },\n",
        "            \"email\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's email address\"\n",
        "            },\n",
        "            \"phone\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's phone number\"\n",
        "            },\n",
        "            \"location\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's location or address\"\n",
        "            },\n",
        "            \"age\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"The user's age\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": []  # All fields are optional\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Sample conversations for demonstration ---\n",
        "sample_conversations = [\n",
        "    [\n",
        "        {\"role\": \"user\", \"content\": \"Hi, my name is John Doe and I'm 25 years old.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Nice to meet you, John! How can I help you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"I live in New York and my email is johndoe@example.com.\"}\n",
        "    ],\n",
        "    [\n",
        "        {\"role\": \"user\", \"content\": \"You can reach me at 555-123-4567.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Thank you for providing your phone number. Is there anything else you'd like to share?\"},\n",
        "        {\"role\": \"user\", \"content\": \"My name is Alice Smith and I'm from London.\"}\n",
        "    ],\n",
        "    [\n",
        "        {\"role\": \"user\", \"content\": \"I'm 30 years old and my email is alice.smith@company.com.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Got it! Is there anything specific you need help with?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Yes, I need help with booking a flight to Paris.\"}\n",
        "    ]\n",
        "]\n",
        "\n",
        "def extract_information(conversation):\n",
        "    \"\"\"Extract structured information from a conversation using function calling\"\"\"\n",
        "    extracted_info = {}\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            messages=conversation,\n",
        "            functions=[user_info_schema],\n",
        "            function_call={\"name\": \"extract_user_information\"}\n",
        "        )\n",
        "\n",
        "        # Check if the model wants to call a function\n",
        "        if response.choices[0].message.function_call:\n",
        "            function_call = response.choices[0].message.function_call\n",
        "            if function_call.name == \"extract_user_information\":\n",
        "                # Parse the arguments\n",
        "                arguments = json.loads(function_call.arguments)\n",
        "\n",
        "                # Update extracted info with new values\n",
        "                for key, value in arguments.items():\n",
        "                    if value:  # Only include if value is not empty\n",
        "                        extracted_info[key] = value\n",
        "\n",
        "                return extracted_info\n",
        "        return {}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during information extraction: {e}\")\n",
        "        return {}\n",
        "\n",
        "def validate_extracted_info(extracted_info):\n",
        "    \"\"\"Validate extracted information against the schema\"\"\"\n",
        "    schema_properties = user_info_schema[\"parameters\"][\"properties\"]\n",
        "    validation_results = {\"valid\": True, \"details\": []}\n",
        "\n",
        "    for field, value in extracted_info.items():\n",
        "        if field in schema_properties:\n",
        "            expected_type = schema_properties[field][\"type\"]\n",
        "            actual_type = type(value).__name__\n",
        "\n",
        "            # Check type compatibility\n",
        "            if (expected_type == \"string\" and isinstance(value, str)) or \\\n",
        "               (expected_type == \"integer\" and isinstance(value, int)):\n",
        "                validation_results[\"details\"].append(\n",
        "                    f\"✓ {field}: Type matches schema ({expected_type})\"\n",
        "                )\n",
        "            else:\n",
        "                validation_results[\"details\"].append(\n",
        "                    f\"✗ {field}: Type mismatch (expected {expected_type}, got {actual_type})\"\n",
        "                )\n",
        "                validation_results[\"valid\"] = False\n",
        "        else:\n",
        "            validation_results[\"details\"].append(\n",
        "                f\"⚠ {field}: Not defined in schema\"\n",
        "            )\n",
        "\n",
        "    # Check for missing required fields (if any were required)\n",
        "    required_fields = user_info_schema[\"parameters\"][\"required\"]\n",
        "    for field in required_fields:\n",
        "        if field not in extracted_info:\n",
        "            validation_results[\"details\"].append(\n",
        "                f\"⚠ {field}: Missing required field\"\n",
        "            )\n",
        "            validation_results[\"valid\"] = False\n",
        "\n",
        "    return validation_results\n",
        "\n",
        "def demonstrate_information_extraction():\n",
        "    \"\"\"Demonstrate information extraction from sample conversations\"\"\"\n",
        "    print(\"=== TASK 2: JSON Schema Classification & Information Extraction ===\")\n",
        "    print(\"Schema defines extraction of: name, email, phone, location, age\\n\")\n",
        "\n",
        "    for i, conversation in enumerate(sample_conversations, 1):\n",
        "        print(f\"\\n--- Sample Conversation {i} ---\")\n",
        "\n",
        "        # Display the conversation\n",
        "        for msg in conversation:\n",
        "            print(f\"{msg['role'].capitalize()}: {msg['content']}\")\n",
        "\n",
        "        # Extract information\n",
        "        extracted_info = extract_information(conversation)\n",
        "\n",
        "        print(\"\\n--- Extracted Information ---\")\n",
        "        if extracted_info:\n",
        "            for key, value in extracted_info.items():\n",
        "                print(f\"{key.capitalize()}: {value}\")\n",
        "        else:\n",
        "            print(\"No information extracted.\")\n",
        "\n",
        "        # Validate against schema\n",
        "        print(\"\\n--- Validation Against Schema ---\")\n",
        "        if extracted_info:\n",
        "            validation = validate_extracted_info(extracted_info)\n",
        "            for detail in validation[\"details\"]:\n",
        "                print(detail)\n",
        "            print(f\"\\nOverall validation: {'PASS' if validation['valid'] else 'FAIL'}\")\n",
        "        else:\n",
        "            print(\"No information to validate.\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# --- Main execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    demonstrate_information_extraction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW_ljeJ_CXGE",
        "outputId": "d6487e12-8aac-4be0-ffa5-42d713f8fa9c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TASK 2: JSON Schema Classification & Information Extraction ===\n",
            "Schema defines extraction of: name, email, phone, location, age\n",
            "\n",
            "\n",
            "--- Sample Conversation 1 ---\n",
            "User: Hi, my name is John Doe and I'm 25 years old.\n",
            "Assistant: Nice to meet you, John! How can I help you today?\n",
            "User: I live in New York and my email is johndoe@example.com.\n",
            "\n",
            "--- Extracted Information ---\n",
            "Age: 25\n",
            "Email: johndoe@example.com\n",
            "Location: New York\n",
            "Name: John Doe\n",
            "\n",
            "--- Validation Against Schema ---\n",
            "✓ age: Type matches schema (integer)\n",
            "✓ email: Type matches schema (string)\n",
            "✓ location: Type matches schema (string)\n",
            "✓ name: Type matches schema (string)\n",
            "\n",
            "Overall validation: PASS\n",
            "\n",
            "============================================================\n",
            "\n",
            "--- Sample Conversation 2 ---\n",
            "User: You can reach me at 555-123-4567.\n",
            "Assistant: Thank you for providing your phone number. Is there anything else you'd like to share?\n",
            "User: My name is Alice Smith and I'm from London.\n",
            "\n",
            "--- Extracted Information ---\n",
            "Location: London\n",
            "Name: Alice Smith\n",
            "Phone: 555-123-4567\n",
            "\n",
            "--- Validation Against Schema ---\n",
            "✓ location: Type matches schema (string)\n",
            "✓ name: Type matches schema (string)\n",
            "✓ phone: Type matches schema (string)\n",
            "\n",
            "Overall validation: PASS\n",
            "\n",
            "============================================================\n",
            "\n",
            "--- Sample Conversation 3 ---\n",
            "User: I'm 30 years old and my email is alice.smith@company.com.\n",
            "Assistant: Got it! Is there anything specific you need help with?\n",
            "User: Yes, I need help with booking a flight to Paris.\n",
            "Error during information extraction: Error code: 400 - {'error': {'message': 'tool call validation failed: parameters for tool extract_user_information did not match schema: errors: [`/age`: expected integer, but got string]', 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=extract_user_information>{\"age\": \"30\", \"email\": \"alice.smith@company.com\"}</function>'}}\n",
            "\n",
            "--- Extracted Information ---\n",
            "No information extracted.\n",
            "\n",
            "--- Validation Against Schema ---\n",
            "No information to validate.\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}